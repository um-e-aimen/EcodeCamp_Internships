{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summary Analysis",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWYFCo-fXX0j"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('d.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ngyhlk_5XsKZ",
        "outputId": "ad048985-9e00-4bd9-80ac-c07f2b799887"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>product_name</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Alex Vando Mens Dress Shirts Regular Fit Long ...</td>\n",
              "      <td>[{'review_heading': 'Very pleasantly surprised...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Unlisted by Kenneth Cole Men's Dress Shirt Sli...</td>\n",
              "      <td>[{'review_heading': 'Thumbs Up', 'text_review'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Kenneth Cole Unlisted Men's Dress Shirt Slim F...</td>\n",
              "      <td>[{'review_heading': 'Very Thin Material -- See...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Van Heusen Men's Dress Shirt Regular Fit Popli...</td>\n",
              "      <td>[{'review_heading': 'Mediocre in Every Aspect....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Amazon Essentials Men's Slim-Fit Wrinkle-Resis...</td>\n",
              "      <td>[{'review_heading': \"Hardly 'Skinny' at all- t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            reviews\n",
              "0           0  ...  [{'review_heading': 'Very pleasantly surprised...\n",
              "1           0  ...  [{'review_heading': 'Thumbs Up', 'text_review'...\n",
              "2           0  ...  [{'review_heading': 'Very Thin Material -- See...\n",
              "3           0  ...  [{'review_heading': 'Mediocre in Every Aspect....\n",
              "4           0  ...  [{'review_heading': \"Hardly 'Skinny' at all- t...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWswL5OoXvpn",
        "outputId": "d6c91288-769b-454c-b92f-57d3b64b0488"
      },
      "source": [
        "import ast\n",
        "import re\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "tot=15\n",
        "text=\"\"\n",
        "f=open('z.txt','w',encoding='utf-8')\n",
        "g=open('final.txt','w',encoding='utf-8')\n",
        "res=[]\n",
        "for i in range(tot):\n",
        "    reviews=ast.literal_eval(df['reviews'][i])\n",
        "    arr=[dict() for x in range(7)]\n",
        "    f.write(\"\\u0332\".join(df['product_name'][i])+\"\\n\\n\\n\")\n",
        "    for review in reviews:\n",
        "        text+=' '+review['text_review']\n",
        "    import re\n",
        "    import nltk\n",
        "    text = re.sub(r'\\[[0-9]*\\]',' ',text)            \n",
        "    text = re.sub(r'\\s+',' ',text)    \n",
        "    clean_text = text.lower()\n",
        "    clean_text = re.sub(r'\\W',' ',clean_text)\n",
        "    clean_text = re.sub(r'\\d',' ',clean_text)\n",
        "    clean_text = re.sub(r'\\s+',' ',clean_text)\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english')+list(string.punctuation))\n",
        "    word2count = {}  \n",
        "    for word in nltk.word_tokenize(clean_text):    \n",
        "        if word not in stop_words:                 \n",
        "            if word not in word2count.keys():\n",
        "                word2count[word]=1\n",
        "            else:\n",
        "                word2count[word]+=1\n",
        "    for key in word2count.keys():                   \n",
        "        word2count[key]=word2count[key]/max(word2count.values())\n",
        "    sent2score = {}\n",
        "    for sentence in sentences:\n",
        "        for word in nltk.word_tokenize(sentence.lower()):\n",
        "            if word in word2count.keys():\n",
        "                if len(sentence.split(' '))<30:\n",
        "                    if sentence not in sent2score.keys():\n",
        "                         sent2score[sentence]=word2count[word]\n",
        "                    else:\n",
        "                        sent2score[sentence]+=word2count[word]\n",
        "    import heapq\n",
        "    best_sentences = heapq.nlargest(4,sent2score,key=sent2score.get)\n",
        "    tmp=\"\"\n",
        "    for sentences in best_sentences:\n",
        "        f.write(sentences+'\\n')\n",
        "        tmp+=sentences+\" \";\n",
        "    tmpObj={\n",
        "        'product':df['product_name'][i],\n",
        "        'summary':tmp[:len(tmp)-1]\n",
        "    }\n",
        "    res.append(tmpObj)\n",
        "    f.write(\"\\n\\n\")\n",
        "g.write(str(res))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6713"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}